{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise-2: Decision Trees [30 points]\n",
    "\n",
    "This notebook covers the implementation and analysis of Decision Tree algorithms for machine learning tasks.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understanding Decision Tree algorithms and their parameters\n",
    "- Implementing Decision Trees for classification and regression\n",
    "- Analyzing tree structure and feature importance\n",
    "- Hyperparameter tuning and model optimization\n",
    "- Handling overfitting and underfitting\n",
    "\n",
    "## Instructions\n",
    "Complete the exercises below by implementing the required code in the designated cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import the necessary libraries for Decision Tree implementation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Preprocessed Data\n",
    "\n",
    "Load the data that was prepared in Exercise-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the preprocessed data from Exercise-1\n",
    "# Example:\n",
    "# X_train = pd.read_csv('../data/X_train_processed.csv')\n",
    "# X_test = pd.read_csv('../data/X_test_processed.csv')\n",
    "# y_train = pd.read_csv('../data/y_train.csv').squeeze()\n",
    "# y_test = pd.read_csv('../data/y_test.csv').squeeze()\n",
    "\n",
    "# TODO: Display the shape of the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Decision Tree Implementation\n",
    "\n",
    "Implement a basic Decision Tree model with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a Decision Tree classifier/regressor with default parameters\n",
    "# dt_model = DecisionTreeClassifier(random_state=42)  # or DecisionTreeRegressor\n",
    "\n",
    "# TODO: Train the model\n",
    "# dt_model.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Make predictions\n",
    "# y_pred = dt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "Evaluate the performance of the Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate and display evaluation metrics\n",
    "# For classification: accuracy, precision, recall, F1-score\n",
    "# For regression: MSE, RMSE, RÂ²\n",
    "\n",
    "# TODO: Display confusion matrix (for classification) or scatter plot (for regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tree Visualization and Analysis\n",
    "\n",
    "Visualize the Decision Tree structure and analyze its components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualize the Decision Tree\n",
    "# Option 1: Using plot_tree (for smaller trees)\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# plot_tree(dt_model, feature_names=X_train.columns, class_names=None, filled=True)\n",
    "# plt.show()\n",
    "\n",
    "# Option 2: Using export_text for text representation\n",
    "# tree_rules = export_text(dt_model, feature_names=list(X_train.columns))\n",
    "# print(tree_rules[:2000])  # Print first 2000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze feature importance\n",
    "# feature_importance = dt_model.feature_importances_\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'feature': X_train.columns,\n",
    "#     'importance': feature_importance\n",
    "# }).sort_values('importance', ascending=False)\n",
    "\n",
    "# TODO: Plot feature importance\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(data=importance_df.head(10), x='importance', y='feature')\n",
    "# plt.title('Top 10 Feature Importances')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning\n",
    "\n",
    "Optimize the Decision Tree model by tuning its hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define hyperparameter grid for GridSearch\n",
    "# param_grid = {\n",
    "#     'max_depth': [3, 5, 10, 15, 20, None],\n",
    "#     'min_samples_split': [2, 5, 10, 20],\n",
    "#     'min_samples_leaf': [1, 2, 4, 8],\n",
    "#     'criterion': ['gini', 'entropy']  # for classification\n",
    "#     # 'criterion': ['mse', 'mae']  # for regression\n",
    "# }\n",
    "\n",
    "# TODO: Perform GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     DecisionTreeClassifier(random_state=42),\n",
    "#     param_grid,\n",
    "#     cv=5,\n",
    "#     scoring='accuracy',  # or appropriate metric for regression\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# TODO: Display best parameters and score\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optimized Model Evaluation\n",
    "\n",
    "Evaluate the performance of the optimized Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the best model from GridSearch\n",
    "# best_dt_model = grid_search.best_estimator_\n",
    "\n",
    "# TODO: Make predictions with the optimized model\n",
    "# y_pred_optimized = best_dt_model.predict(X_test)\n",
    "\n",
    "# TODO: Evaluate the optimized model\n",
    "# Compare performance with the basic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Overfitting Analysis\n",
    "\n",
    "Analyze the relationship between model complexity and overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create learning curves to analyze overfitting\n",
    "# Test different max_depth values and plot training vs validation scores\n",
    "\n",
    "# max_depths = range(1, 21)\n",
    "# train_scores = []\n",
    "# val_scores = []\n",
    "\n",
    "# for depth in max_depths:\n",
    "#     dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "#     dt.fit(X_train, y_train)\n",
    "#     \n",
    "#     train_score = dt.score(X_train, y_train)\n",
    "#     val_score = dt.score(X_test, y_test)\n",
    "#     \n",
    "#     train_scores.append(train_score)\n",
    "#     val_scores.append(val_score)\n",
    "\n",
    "# TODO: Plot the learning curves\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(max_depths, train_scores, 'o-', label='Training Score')\n",
    "# plt.plot(max_depths, val_scores, 'o-', label='Validation Score')\n",
    "# plt.xlabel('Max Depth')\n",
    "# plt.ylabel('Score')\n",
    "# plt.title('Training vs Validation Score by Max Depth')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cross-Validation Analysis\n",
    "\n",
    "Perform cross-validation to get a more robust evaluation of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform k-fold cross-validation\n",
    "# cv_scores = cross_val_score(\n",
    "#     best_dt_model, \n",
    "#     X_train, \n",
    "#     y_train, \n",
    "#     cv=5, \n",
    "#     scoring='accuracy'  # or appropriate metric\n",
    "# )\n",
    "\n",
    "# TODO: Display cross-validation results\n",
    "# print(f\"Cross-validation scores: {cv_scores}\")\n",
    "# print(f\"Mean CV score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Interpretation\n",
    "\n",
    "Interpret the Decision Tree model and extract insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extract and analyze decision rules\n",
    "# Create a function to extract meaningful rules from the tree\n",
    "\n",
    "# TODO: Identify the most important decision paths\n",
    "\n",
    "# TODO: Analyze how different features contribute to the final predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Comparison with Different Tree Configurations\n",
    "\n",
    "Compare Decision Trees with different configurations and criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compare different splitting criteria (gini vs entropy for classification)\n",
    "# TODO: Compare different pruning strategies\n",
    "# TODO: Create a comparison table of different configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "Summarize the findings from the Decision Tree analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "1. How does the complexity of the Decision Tree affect its performance?\n",
    "2. What are the advantages and disadvantages of Decision Trees for your dataset?\n",
    "3. How do different hyperparameters influence the model's behavior?\n",
    "4. What insights can you gain from the feature importance analysis?\n",
    "5. How would you prevent overfitting in Decision Trees?\n",
    "\n",
    "**TODO: Answer the reflection questions above in markdown cells below.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}