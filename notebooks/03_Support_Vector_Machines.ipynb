{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise-3: Support Vector Machines (SVM) [30 points]\n",
    "\n",
    "This notebook covers the implementation and analysis of Support Vector Machine algorithms for machine learning tasks.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understanding SVM algorithms and their mathematical foundations\n",
    "- Implementing SVMs for classification and regression\n",
    "- Exploring different kernel functions and their effects\n",
    "- Hyperparameter tuning for optimal performance\n",
    "- Analyzing decision boundaries and support vectors\n",
    "- Handling non-linearly separable data\n",
    "\n",
    "## Instructions\n",
    "Complete the exercises below by implementing the required code in the designated cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import the necessary libraries for SVM implementation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Preprocessed Data\n",
    "\n",
    "Load the data that was prepared in Exercise-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the preprocessed data from Exercise-1\n",
    "# Example:\n",
    "# X_train = pd.read_csv('../data/X_train_processed.csv')\n",
    "# X_test = pd.read_csv('../data/X_test_processed.csv')\n",
    "# y_train = pd.read_csv('../data/y_train.csv').squeeze()\n",
    "# y_test = pd.read_csv('../data/y_test.csv').squeeze()\n",
    "\n",
    "# TODO: Display the shape of the datasets\n",
    "# Ensure data is properly scaled for SVM (SVMs are sensitive to feature scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Scaling for SVM\n",
    "\n",
    "Ensure data is properly scaled since SVMs are sensitive to feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Scale the features if not already done\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# TODO: Convert back to DataFrame for easier handling\n",
    "# X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "# X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear SVM Implementation\n",
    "\n",
    "Start with a linear SVM to establish baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a linear SVM classifier/regressor\n",
    "# linear_svm = SVC(kernel='linear', random_state=42)  # or SVR for regression\n",
    "\n",
    "# TODO: Train the model\n",
    "# linear_svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# TODO: Make predictions\n",
    "# y_pred_linear = linear_svm.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Linear SVM Evaluation\n",
    "\n",
    "Evaluate the performance of the linear SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate and display evaluation metrics\n",
    "# For classification: accuracy, precision, recall, F1-score\n",
    "# For regression: MSE, RMSE, RÂ²\n",
    "\n",
    "# TODO: Display confusion matrix (for classification)\n",
    "# TODO: Analyze support vectors\n",
    "# print(f\"Number of support vectors: {linear_svm.n_support_}\")\n",
    "# print(f\"Support vector indices: {linear_svm.support_[:10]}...\")  # First 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Kernel SVM Implementation\n",
    "\n",
    "Implement SVMs with different kernel functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement SVMs with different kernels\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "svm_models = {}\n",
    "svm_predictions = {}\n",
    "svm_scores = {}\n",
    "\n",
    "# TODO: Train models with each kernel\n",
    "# for kernel in kernels:\n",
    "#     svm = SVC(kernel=kernel, random_state=42)\n",
    "#     svm.fit(X_train_scaled, y_train)\n",
    "#     \n",
    "#     predictions = svm.predict(X_test_scaled)\n",
    "#     score = svm.score(X_test_scaled, y_test)\n",
    "#     \n",
    "#     svm_models[kernel] = svm\n",
    "#     svm_predictions[kernel] = predictions\n",
    "#     svm_scores[kernel] = score\n",
    "#     \n",
    "#     print(f\"{kernel.upper()} kernel - Test score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Kernel Comparison and Analysis\n",
    "\n",
    "Compare the performance of different kernel functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a comparison chart of kernel performances\n",
    "# kernel_comparison = pd.DataFrame({\n",
    "#     'Kernel': list(svm_scores.keys()),\n",
    "#     'Test Score': list(svm_scores.values())\n",
    "# })\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(data=kernel_comparison, x='Kernel', y='Test Score')\n",
    "# plt.title('SVM Performance Comparison by Kernel Type')\n",
    "# plt.ylabel('Test Score')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Tuning\n",
    "\n",
    "Optimize SVM hyperparameters for the best performing kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define hyperparameter grid for the best kernel\n",
    "# For RBF kernel example:\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100, 1000],\n",
    "#     'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "#     'kernel': ['rbf']\n",
    "# }\n",
    "\n",
    "# TODO: Perform GridSearchCV\n",
    "# grid_search = GridSearchCV(\n",
    "#     SVC(random_state=42),\n",
    "#     param_grid,\n",
    "#     cv=5,\n",
    "#     scoring='accuracy',  # or appropriate metric\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "# grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# TODO: Display best parameters and score\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Optimized SVM Evaluation\n",
    "\n",
    "Evaluate the performance of the optimized SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the best model from GridSearch\n",
    "# best_svm = grid_search.best_estimator_\n",
    "\n",
    "# TODO: Make predictions with the optimized model\n",
    "# y_pred_optimized = best_svm.predict(X_test_scaled)\n",
    "\n",
    "# TODO: Evaluate the optimized model\n",
    "# Compare with previous models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Decision Boundary Visualization\n",
    "\n",
    "Visualize decision boundaries for different SVM configurations (for 2D data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: If dataset has many features, select 2 most important features for visualization\n",
    "# For demonstration purposes, you can use PCA to reduce to 2D\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# pca = PCA(n_components=2)\n",
    "# X_train_2d = pca.fit_transform(X_train_scaled)\n",
    "# X_test_2d = pca.transform(X_test_scaled)\n",
    "\n",
    "# TODO: Train SVM on 2D data and visualize decision boundaries\n",
    "# for kernel in ['linear', 'rbf']:\n",
    "#     svm_2d = SVC(kernel=kernel, random_state=42)\n",
    "#     svm_2d.fit(X_train_2d, y_train)\n",
    "#     \n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plot_decision_regions(X_train_2d, y_train.values, clf=svm_2d, legend=2)\n",
    "#     plt.title(f'SVM Decision Boundary - {kernel.upper()} Kernel')\n",
    "#     plt.xlabel('First Principal Component')\n",
    "#     plt.ylabel('Second Principal Component')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Support Vector Analysis\n",
    "\n",
    "Analyze the support vectors and their importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze support vectors from the best model\n",
    "# print(f\"Number of support vectors: {best_svm.n_support_}\")\n",
    "# print(f\"Total support vectors: {len(best_svm.support_)}\")\n",
    "# print(f\"Percentage of support vectors: {len(best_svm.support_) / len(X_train_scaled) * 100:.2f}%\")\n",
    "\n",
    "# TODO: Examine the characteristics of support vectors\n",
    "# support_vectors = X_train_scaled.iloc[best_svm.support_]\n",
    "# print(\"\\nSupport vector statistics:\")\n",
    "# print(support_vectors.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Regularization Parameter (C) Analysis\n",
    "\n",
    "Analyze the effect of the regularization parameter C on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test different C values and plot the effect\n",
    "# c_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "# train_scores = []\n",
    "# test_scores = []\n",
    "# n_support_vectors = []\n",
    "\n",
    "# for c in c_values:\n",
    "#     svm = SVC(C=c, kernel='rbf', random_state=42)\n",
    "#     svm.fit(X_train_scaled, y_train)\n",
    "#     \n",
    "#     train_score = svm.score(X_train_scaled, y_train)\n",
    "#     test_score = svm.score(X_test_scaled, y_test)\n",
    "#     n_sv = len(svm.support_)\n",
    "#     \n",
    "#     train_scores.append(train_score)\n",
    "#     test_scores.append(test_score)\n",
    "#     n_support_vectors.append(n_sv)\n",
    "\n",
    "# TODO: Plot the results\n",
    "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# ax1.semilogx(c_values, train_scores, 'o-', label='Training Score')\n",
    "# ax1.semilogx(c_values, test_scores, 'o-', label='Test Score')\n",
    "# ax1.set_xlabel('C (Regularization Parameter)')\n",
    "# ax1.set_ylabel('Score')\n",
    "# ax1.set_title('SVM Performance vs Regularization Parameter')\n",
    "# ax1.legend()\n",
    "# ax1.grid(True)\n",
    "\n",
    "# ax2.semilogx(c_values, n_support_vectors, 'ro-')\n",
    "# ax2.set_xlabel('C (Regularization Parameter)')\n",
    "# ax2.set_ylabel('Number of Support Vectors')\n",
    "# ax2.set_title('Support Vectors vs Regularization Parameter')\n",
    "# ax2.grid(True)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Cross-Validation Analysis\n",
    "\n",
    "Perform cross-validation to get robust performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform k-fold cross-validation with the best model\n",
    "# cv_scores = cross_val_score(\n",
    "#     best_svm,\n",
    "#     X_train_scaled,\n",
    "#     y_train,\n",
    "#     cv=5,\n",
    "#     scoring='accuracy'  # or appropriate metric\n",
    "# )\n",
    "\n",
    "# TODO: Display cross-validation results\n",
    "# print(f\"Cross-validation scores: {cv_scores}\")\n",
    "# print(f\"Mean CV score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "\n",
    "# TODO: Compare with other models from previous exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Feature Importance Analysis\n",
    "\n",
    "Analyze feature importance in SVM (using permutation importance or coefficients for linear SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For linear SVM, analyze feature coefficients\n",
    "# if best_svm.kernel == 'linear':\n",
    "#     feature_importance = np.abs(best_svm.coef_[0])\n",
    "#     importance_df = pd.DataFrame({\n",
    "#         'feature': X_train_scaled.columns,\n",
    "#         'importance': feature_importance\n",
    "#     }).sort_values('importance', ascending=False)\n",
    "#     \n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     sns.barplot(data=importance_df.head(10), x='importance', y='feature')\n",
    "#     plt.title('Linear SVM Feature Coefficients (Absolute Values)')\n",
    "#     plt.show()\n",
    "\n",
    "# TODO: For non-linear kernels, use permutation importance\n",
    "# from sklearn.inspection import permutation_importance\n",
    "# perm_importance = permutation_importance(best_svm, X_test_scaled, y_test, n_repeats=10, random_state=42)\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'feature': X_train_scaled.columns,\n",
    "#     'importance': perm_importance.importances_mean\n",
    "# }).sort_values('importance', ascending=False)\n",
    "# \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.barplot(data=importance_df.head(10), x='importance', y='feature')\n",
    "# plt.title('SVM Permutation Feature Importance')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Model Comparison Summary\n",
    "\n",
    "Compare SVM with the Decision Tree model from Exercise-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a comparison table of SVM vs Decision Tree\n",
    "# Include metrics like accuracy, training time, prediction time, interpretability\n",
    "\n",
    "# TODO: Discuss the trade-offs between the two approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "Summarize the findings from the SVM analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "1. How do different kernel functions affect SVM performance on your dataset?\n",
    "2. What is the relationship between the regularization parameter C and model complexity?\n",
    "3. How does the number of support vectors relate to model generalization?\n",
    "4. When would you choose SVM over Decision Trees and vice versa?\n",
    "5. How does feature scaling impact SVM performance compared to Decision Trees?\n",
    "6. What are the computational considerations when using different SVM kernels?\n",
    "\n",
    "**TODO: Answer the reflection questions above in markdown cells below.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
