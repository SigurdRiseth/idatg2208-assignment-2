{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise-1: Data Preparation [10 points]\n",
    "\n",
    "This notebook covers the fundamental aspects of data preparation for machine learning tasks.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understanding data loading and exploration\n",
    "- Data cleaning and preprocessing techniques\n",
    "- Feature engineering and selection\n",
    "- Data splitting for training and testing\n",
    "\n",
    "## Instructions\n",
    "Complete the exercises below by implementing the required code in the designated cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import the necessary Python libraries for data manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Load your dataset and perform initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load your dataset\n",
    "# Example: df = pd.read_csv('../data/your_dataset.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "# TODO: Implement data loading and basic exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Perform exploratory data analysis to understand the dataset structure and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display dataset shape, column names, and data types\n",
    "\n",
    "# TODO: Check for missing values\n",
    "\n",
    "# TODO: Display summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create visualizations to understand data distribution\n",
    "# - Histograms for numerical features\n",
    "# - Count plots for categorical features\n",
    "# - Correlation matrix heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning\n",
    "\n",
    "Handle missing values, outliers, and inconsistencies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle missing values\n",
    "# - Identify columns with missing values\n",
    "# - Decide on appropriate strategy (drop, impute, etc.)\n",
    "# - Implement the chosen strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Detect and handle outliers\n",
    "# - Use statistical methods (IQR, Z-score) or visualization\n",
    "# - Decide whether to remove, cap, or transform outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "Create new features or transform existing ones to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feature engineering tasks\n",
    "# - Create new features from existing ones\n",
    "# - Encode categorical variables\n",
    "# - Scale numerical features if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Splitting\n",
    "\n",
    "Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Separate features and target variable\n",
    "# X = ...\n",
    "# y = ...\n",
    "\n",
    "# TODO: Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# TODO: Display the shapes of the resulting datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Preprocessing Pipeline\n",
    "\n",
    "Create a preprocessing pipeline for consistent data transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create preprocessing pipeline\n",
    "# - Include scaling, encoding, and any other necessary transformations\n",
    "# - Fit the pipeline on training data\n",
    "# - Transform both training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "Summarize the data preparation process and prepare for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save the preprocessed data for use in subsequent exercises\n",
    "# Example: \n",
    "# pd.DataFrame(X_train_processed).to_csv('../data/X_train_processed.csv', index=False)\n",
    "# pd.DataFrame(X_test_processed).to_csv('../data/X_test_processed.csv', index=False)\n",
    "# pd.Series(y_train).to_csv('../data/y_train.csv', index=False)\n",
    "# pd.Series(y_test).to_csv('../data/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "1. What challenges did you encounter during data preparation?\n",
    "2. How did you decide on the strategy for handling missing values?\n",
    "3. What feature engineering techniques did you apply and why?\n",
    "4. How might different preprocessing choices affect model performance?\n",
    "\n",
    "**TODO: Answer the reflection questions above in markdown cells below.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}